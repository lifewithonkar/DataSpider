ğŸ¦ TIAA Bank Loan Rates Scraper

ğŸ“Œ Project Overview

This project scrapes loan and mortgage rate data from financial websites (e.g., Bankrate) using Scrapy, and automates the scraping process using GitHub Actions.

ğŸ”„ Scrapy â†’ Collects loan rate data (product, interest rate, APR, term, lender, date).

â˜ï¸ GitHub Actions â†’ Runs the spider daily at a scheduled time.

ğŸ’¾ Storage â†’ Saves data into JSON and CSV files (with option for S3 in future).



ğŸš€ Features

Automated scraping of mortgage/loan rates.

Scheduled runs via GitHub Actions (daily at set IST time).

Data saved in CSV (historical data) and JSON (latest snapshot).

Easy to extend for cloud storage (AWS S3) or databases.



ğŸ“‚ Project Structure

loanrates-g5/

â”œâ”€â”€ loanrates/                   # Main Scrapy project folder

â”‚   â”œâ”€â”€ spiders/                 # All spiders & helper scripts

â”‚   â”‚   â”œâ”€â”€ data/                # Scraped data outputs

â”‚   â”‚   â”‚   â”œâ”€â”€ bankrate.json    # Latest scraped data

â”‚   â”‚   â”‚   â”œâ”€â”€ bankrates.csv    # Historical data (appended daily)

â”‚   â”‚   â”‚   â””â”€â”€ log/             # Logs folder

â”‚   â”‚   â”œâ”€â”€ append_json_to_csv.py# Script to append JSON to CSV

â”‚   â”‚   â”œâ”€â”€ bankrate_spider.py   # Main Scrapy spider

â”‚   â”‚   â”œâ”€â”€ __init__.py

â”‚   â”‚

â”‚   â”œâ”€â”€ items.py                 # Item definitions for scraped fields

â”‚   â”œâ”€â”€ middlewares.py           # Custom middlewares

â”‚   â”œâ”€â”€ pipelines.py             # Data processing pipelines

â”‚   â”œâ”€â”€ settings.py              # Scrapy project settings

â”‚   â””â”€â”€ __pycache__/

â”‚

â”œâ”€â”€ .github/workflows/ci.yml     # GitHub Actions workflow (automation)

â”œâ”€â”€ requirements.txt             # Python dependencies

â””â”€â”€ README.md                    # Project documentation



âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/lifewithonkar/spider.git
cd spider

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run Scrapy Spider (locally)
python bankrate_loans.py


Output â†’ bankrate_loans.json (latest snapshot)

Output â†’ bankrate_rates_history.csv (appended daily history)



ğŸ› ï¸ Automation with GitHub Actions

Workflow runs daily at 10:30 AM IST.

Executes the Scrapy spider and updates JSON + CSV files.

Workflow file: .github/workflows/ci.yml



ğŸ“Œ Future Enhancements

Store scraped data in AWS S3.

Build a Django/Flask UI to display results.

Add user authentication for dashboard access.

Create data visualization (charts, trends, comparisons).
